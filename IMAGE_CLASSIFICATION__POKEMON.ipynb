{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.glob at 0x0000026D0D752228>\n"
     ]
    }
   ],
   "source": [
    "p=Path(r\"C:\\Users\\zeesh\\OneDrive\\Desktop\\pokemon_classification\\datasets\")\n",
    "dirs=p.glob(\"*\")\n",
    "print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data=[]\n",
    "labels_dict={\"Bulbasaur\":0 , \"Charmander\":1 , \"Pikachu\":2}\n",
    "label2pokemon={0:\"Bulbasaur\", 1 :\"Charmander\", 2:\"Pikachu\"}\n",
    "labels=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulbasaur\n",
      "111\n",
      "Charmander\n",
      "146\n",
      "Pikachu\n",
      "117\n"
     ]
    }
   ],
   "source": [
    "for folder_dir in dirs:\n",
    "    label=str(folder_dir).split(\"\\\\\")[-1]\n",
    "    print(label)\n",
    "    cnt=0\n",
    "    for img_path in folder_dir.glob(\"*.jpg\"):\n",
    "        img=image.load_img(img_path,target_size=(100,100))\n",
    "        image_arr=image.img_to_array(img)\n",
    "        image_data.append(image_arr)\n",
    "        labels.append(labels_dict[label])\n",
    "        cnt+=1\n",
    "    print(cnt)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374\n",
      "374\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(374, 100, 100, 3)\n",
      "(374,)\n"
     ]
    }
   ],
   "source": [
    "x=np.array(image_data)\n",
    "y=np.array(labels)\n",
    "\n",
    "#normlise\n",
    "x=x/255.0\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawImg(x,labels):\n",
    "    plt.imshow(x)\n",
    "    plt.title(label2pokemon[labels])\n",
    "    plt.style.use(\"seaborn\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "x,y=shuffle(x,y,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 100, 100, 3) (299,)\n",
      "(75, 100, 100, 3) (75,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "print(xtrain.shape,ytrain.shape)\n",
    "print(xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    e=np.exp(a)\n",
    "    ans=e/np.sum(e,axis=1,keepdims=True)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self,input_size,layers,output_size):\n",
    "        np.random.seed(0)\n",
    "        \n",
    "        model={}\n",
    "        #first layer\n",
    "        model['w1']=np.random.randn(input_size,layers[0])  ##3,4\n",
    "        model['b1']=np.zeros((1,layers[0]))    ##1,4\n",
    "        \n",
    "        model['w2']=np.random.randn(layers[0],layers[1])  ##4,3\n",
    "        model['b2']=np.zeros((1,layers[1]))         ##1,3\n",
    "        \n",
    "        model['w3']=np.random.randn(layers[1],output_size)  ##4,2\n",
    "        model['b3']=np.zeros((1,output_size))      ###1,2\n",
    "        #self.activation_output=()\n",
    "        self.model=model\n",
    "    def forward(self,x):\n",
    "        w1,w2,w3=self.model['w1'],self.model['w2'],self.model['w3']\n",
    "        b1,b2,b3=self.model['b1'],self.model['b2'],self.model['b3']\n",
    "        \n",
    "        z1=np.dot(x,w1) + b1    #x--> m,n w1-->n,layer1   ======m,4 +   1,4\n",
    "        a1=np.tanh(z1)\n",
    "        \n",
    "        z2=np.dot(a1,w2) + b2  \n",
    "        a2=np.tanh(z2)\n",
    "        \n",
    "        z3=np.dot(a2,w3) + b3\n",
    "        y_=softmax(z3)\n",
    "        self.activation_output=(a1,a2,y_)\n",
    "        #print(y_.shape)\n",
    "        return y_\n",
    "    def backward(self,x,y,learning_rate):\n",
    "        w1,w2,w3=self.model['w1'],self.model['w2'],self.model['w3']\n",
    "        b1,b2,b3=self.model['b1'],self.model['b2'],self.model['b3']\n",
    "        a1,a2,y_=self.activation_output\n",
    "        m=x.shape[0]\n",
    "        delta3=y_-y\n",
    "        dw3=np.dot(a2.T,delta3)\n",
    "        db3=np.sum(delta3,axis=0)/float(m)\n",
    "        \n",
    "        delta2=(1-np.square(a2))*np.dot(delta3,w3.T)\n",
    "        dw2=np.dot(a1.T,delta2)\n",
    "        db2=np.sum(delta2,axis=0)/float(m)\n",
    "        \n",
    "        delta1=(1-np.square(a1))*np.dot(delta2,w2.T)\n",
    "        dw1=np.dot(x.T,delta1)\n",
    "        db1=np.sum(delta1,axis=0)/float(m)\n",
    "        \n",
    "        ###update\n",
    "        self.model['w1']-=learning_rate*dw1\n",
    "        self.model['b1']-=learning_rate*db1\n",
    "        \n",
    "        self.model['w2']-=learning_rate*dw2\n",
    "        self.model['b2']-=learning_rate*db2\n",
    "        \n",
    "        self.model['w3']-=learning_rate*dw3\n",
    "        self.model['b3']-=learning_rate*db3\n",
    "        \n",
    "    def predict(self,x):\n",
    "        y_out=self.forward(x)\n",
    "        print(y_out.shape )\n",
    "        return np.argmax(y_out,axis=1)      \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(self):\n",
    "    w1,w2,w3=self.model['w1'],self.model['w2'],self.model['w3']\n",
    "    a1,a2,y_=self.activation_output\n",
    "        \n",
    "    print(\"w1\"%w1.shape)\n",
    "    print(\"a1\"%a1.shape)\n",
    "        \n",
    "    print(\"w2\"%w2.shape)\n",
    "    print(\"a2\"%a2.shape)\n",
    "              \n",
    "    print(\"w3\"%w3.shape)\n",
    "    print(\"y_\"%y_.shape)\n",
    "    \n",
    "def loss(y_oht,p):\n",
    "    l=-np.mean(y_oht*np.log(p))\n",
    "    return l\n",
    "def onehot(y,depth):\n",
    "    m=y.shape[0]\n",
    "    y_oht=np.zeros((m,depth))\n",
    "    y_oht[np.arange(m),y]=1\n",
    "    return y_oht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x,y,model,epochs,learning_rate):\n",
    "    training_loss=[]\n",
    "    classes=3\n",
    "    y_oht=onehot(y,classes)\n",
    "    \n",
    "    for ix in range(epochs):\n",
    "        Y_=model.forward(x)\n",
    "        l=loss(y_oht,Y_)\n",
    "        training_loss.append(l)\n",
    "        model.backward(x,y_oht,learning_rate)\n",
    "        \n",
    "    return training_loss        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralNetwork(input_size=30000,layers=[100,50],output_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 30000) (299, 1)\n",
      "(75, 30000) (75, 1)\n"
     ]
    }
   ],
   "source": [
    "xtrain=xtrain.reshape(xtrain.shape[0],-1)\n",
    "ytrain=ytrain.reshape(ytrain.shape[0],-1)\n",
    "xtest=xtest.reshape(xtest.shape[0],-1)\n",
    "ytest=ytest.reshape(ytest.shape[0],-1)\n",
    "print(xtrain.shape,ytrain.shape)\n",
    "print(xtest.shape,ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "c:\\users\\zeesh\\anaconda3\\envs\\tensorflow_cpu\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "l=train(xtrain,ytrain,model,500,0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.719030411863644, 6.538752670792522, 5.313229687479574, 4.262247543682777, 3.599319838798477, 3.3314389696517566, 2.9207710754982443, 2.7639557384537525, 2.508815039059061, 2.415950045202905, 2.3569181433304496, 2.346838768061712, 2.292012026819177, 2.1952806400212186, 2.0253143539942275, 1.972710832341914, 1.9067389192265836, 1.9176186355241398, 1.8655934959183864, 1.8244347933896128, 1.7763704442673287, 1.7297552717115419, 1.688325736688936, 1.6486204988984674, 1.632562614997831, 1.6110330640253032, 1.573515310133807, 1.56187060342589, 1.5459118329016996, 1.5359657263140514, 1.5237007115842296, 1.5189762332916215, 1.5025267370602633, 1.492576023200881, 1.477366335201408, 1.475306109454324, 1.4703183205340218, 1.454035403627672, 1.443905110101542, 1.4388959343977061, 1.4298169683633906, 1.4305166655335835, 1.4399371555646052, 1.4187253734549758, 1.4172285628558106, 1.423454816841356, 1.4152224173305508, 1.4052161921374253, 1.3980586013722598, 1.3914897299596698, 1.3908163707561332, 1.3811702640110366, 1.374716947310136, 1.3693220400096866, 1.3660811233296395, 1.3618502171404485, 1.3794190701554723, 1.3636009479339255, 1.3590041168326354, 1.3518337907546416, 1.348124257258051, 1.3425997769064784, 1.339560416096425, 1.3345241503208713, 1.3329492393189093, 1.330547366078224, 1.3278386311435162, 1.3220397420346315, 1.3157025958544724, 1.3147494473841663, 1.3188067108320756, 1.3185872490130568, 1.3039542838765705, 1.3060715063015398, 1.3045597728489184, 1.3016381215062074, 1.3079200778002273, 1.3109900165873882, 1.311014577025393, 1.3072011061991335, 1.3128066851279696, 1.3143083952147536, 1.3081931760210335, 1.3052856691447496, 1.3102330254790497, 1.3105008569532675, 1.3088065843701269, 1.3081076528852897, 1.3099526568595192, 1.3385420814624953, 1.3144187824185989, 1.3136118593832098, 1.3104078672144168, 1.3051082101667548, 1.3047486523416776, 1.3080451083210878, 1.3029134862567318, 1.3040303408973655, 1.295158367319285, 1.2975673403630812, 1.2943160936256126, 1.2894144066861757, 1.2910239926659246, 1.2877384142328345, 1.2834046662920988, 1.2799585188446416, 1.2799679120869902, 1.277433151337743, 1.2711903850655581, 1.269961001482559, 1.270534310105972, 1.260188830119064, 1.2601151909999815, 1.2587969270951898, 1.2766470853790397, 1.2737142773944363, 1.2593909691218743, 1.2598592973395886, 1.261182139240633, 1.2611937178053845, 1.2613918638403625, 1.262099743663776, 1.2617794844818087, 1.2623282850110824, 1.2626343393973207, 1.2574055790429373, 1.2555383118030627, 1.253684974068675, 1.2511112120452186, 1.2480856888565852, 1.2460408704438377, 1.2448053501304104, 1.2439247006601628, 1.2431396083558903, 1.2423466289463958, 1.2415125032760386, 1.2406092702709184, 1.239586226482043, 1.2386436378434218, 1.2373500772977384, 1.2360945276861854, 1.2348369336732625, 1.2338147654194238, 1.2333795498899984, 1.236150370967385, 1.2360840549369718, 1.2368018254575919, 1.2395968870781169, 1.2395803120594542, 1.2395331121574935, 1.2394813451346738, 1.2394025085896183, 1.2393140053610026, 1.2392252181643866, 1.2391275752383768, 1.2390334650695018, 1.2389224624412938, 1.238785799333947, 1.2386914904762565, 1.2405590839074139, 1.2372474883397668, 1.2407683372635399, 1.2401101925864517, 1.2395448105223859, 1.2388442250609424, 1.2380549785099122, 1.2374756455095748, 1.2372083833305922, 1.2370109021410154, 1.2367142964099482, 1.2367205587985537, 1.2366405220701158, 1.236421323867844, 1.2364795906248711, 1.2363611293178165, 1.2364199339095996, 1.23648514480359, 1.2366618222813364, 1.2369365769471252, 1.2372052496572263, 1.237415297302582, 1.2374713326319289, 1.2375025071513406, 1.23742784258276, 1.2373075063240802, 1.2371489168719285, 1.2369523026781566, 1.2367107852419736, 1.236407366738868, 1.236005258059408, 1.2354148444164572, 1.2341260591248504, 1.2288036753230003, 1.2312056570672294, 1.2304243132278159, 1.2294754426374253, 1.2287810511379187, 1.2283721386480828, 1.228102741975209, 1.2278919648018265, 1.2276999459174964, 1.2275113782917315, 1.2273132598779344, 1.2270923718258042, 1.2267074899899308, 1.215497611115251, 1.2149058418771845, 1.2142746375145135, 1.213586686127469, 1.2128047392008452, 1.2118113236411117, 1.211234490138447, 1.2090650367274942, 1.2077862765231373, 1.2071688885663536, 1.206897610493651, 1.2067336003421505, 1.206836153156098, 1.2091398358047873, 1.2085268935397286, 1.2081271838065395, 1.2055359778264096, 1.2051056319561795, 1.2046164412363862, 1.2044074468536603, 1.205103961920609, 1.2062543270278188, 1.207073281522246, 1.2075356754510762, 1.207784467560071, 1.2079101204661007, 1.2079601398063031, 1.207959437961132, 1.2079207715061806, 1.207848945294251, 1.2077400174297894, 1.2075607094356664, 1.2064820176661237, 1.2060126408976566, 1.2058057625288974, 1.2044534280955108, 1.2044304441281848, 1.2043531221163257, 1.2042903854673956, 1.2042113828581262, 1.2041207112916088, 1.204038496970499, 1.2039493510444303, 1.2038567428358584, 1.2037612955633459, 1.203663295525345, 1.2035640871737365, 1.2034640010953042, 1.203363483343346, 1.2032622228406447, 1.2031585311702118, 1.203051717351792, 1.202942766343025, 1.2028320358799058, 1.202719600373417, 1.2026053265584986, 1.2024889685898321, 1.2023703659859803, 1.2022490001846153, 1.2021245499670246, 1.201996162106002, 1.2018631401434066, 1.2017240422178292, 1.2015773327340784, 1.20142030579603, 1.2012494069176844, 1.2010586655362359, 1.2008387921349435, 1.2005732690434605, 1.2002312820999221, 1.199745425278694, 1.19888508812297, 1.191105550504563, 1.1907034565730887, 1.190141729805211, 1.1892976548649599, 1.187605482528786, 1.1831893548021564, 1.1823132065202349, 1.1819066892213637, 1.1817810131411146, 1.1815740396796992, 1.1815007063716383, 1.1812600767188774, 1.1812244641968475, 1.180894171522462, 1.1808429981858537, 1.1804030006997355, 1.1801133499149177, 1.1793642025851407, 1.1786291436599325, 1.1780308053443271, 1.1778611654644209, 1.1777187758322827, 1.1776441486010503, 1.177546633306719, 1.1774726984522477, 1.177384209914044, 1.177309026911185, 1.177222614983247, 1.1771460707330956, 1.1770598932998841, 1.1769813321613984, 1.176894375774526, 1.1768128831346913, 1.1767238572911416, 1.1766379360921693, 1.1765445818912788, 1.1764512076079123, 1.1763486922012794, 1.1762403675852444, 1.1761154535253895, 1.1759674389996597, 1.1757670346723554, 1.1754470221500033, 1.174774265611551, 1.1732222928279006, 1.1721304613848451, 1.1719660955174074, 1.171846087810045, 1.1717243385252367, 1.1715869497719313, 1.1714210798034947, 1.1712049211407742, 1.1708985740186006, 1.170424764825266, 1.169671218161014, 1.1687246524461843, 1.1687213918102755, 1.1696619487268958, 1.1701429026920427, 1.170347733540164, 1.1704412241121391, 1.1704819939062145, 1.170494070903059, 1.1704889000613108, 1.17047258281983, 1.170448657559577, 1.1704193131473275, 1.170385974284401, 1.1703496070699033, 1.1703108890053442, 1.1702703086627197, 1.170228226730654, 1.1701849148234267, 1.1701405809667769, 1.1700953868369433, 1.170049459774918, 1.1700029014731979, 1.169955794638428, 1.1699082087124162, 1.1698602059273246, 1.1698118499764625, 1.1697632229051875, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299, 3)\n",
      "82.0\n"
     ]
    }
   ],
   "source": [
    "output=model.predict(xtrain)\n",
    "acc=np.sum(output==ytrain)/float(ytrain.shape[0])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
